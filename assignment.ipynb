{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "13ad028b-72b7-43ed-aa78-96fd4e518040",
      "metadata": {
        "id": "13ad028b-72b7-43ed-aa78-96fd4e518040"
      },
      "source": [
        "# Assignment: Data Wrangling\n",
        "### `! git clone https://github.com/ds3001f25/wrangling_assignment.git`\n",
        "### Do Q1 and Q2\n",
        "### Reading material: `tidy_data.pdf`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da879ea7-8aac-48a3-b6c2-daea56d2e072",
      "metadata": {
        "id": "da879ea7-8aac-48a3-b6c2-daea56d2e072"
      },
      "source": [
        "**Q1.** This question provides some practice cleaning variables which have common problems.\n",
        "1. Numeric variable: For `./data/airbnb_hw.csv`, clean the `Price` variable as well as you can, and explain the choices you make. How many missing values do you end up with? (Hint: What happens to the formatting when a price goes over 999 dollars, say from 675 to 1,112?)\n",
        "2. Categorical variable: For the Minnesota police use of for data, `./data/mn_police_use_of_force.csv`, clean the `subject_injury` variable, handling the NA's; this gives a value `Yes` when a person was injured by police, and `No` when no injury occurred. What proportion of the values are missing? Is this a concern? Cross-tabulate your cleaned `subject_injury` variable with the `force_type` variable. Are there any patterns regarding when the data are missing?\n",
        "3. Dummy variable: For the pretrial data covered in the lecture `./data/justice_data.parquet`, clean the `WhetherDefendantWasReleasedPretrial` variable as well as you can, and, in particular, replace missing values with `np.nan`.\n",
        "4. Missing values, not at random: For the pretrial data covered in the lecture, clean the `ImposedSentenceAllChargeInContactEvent` variable as well as you can, and explain the choices you make. (Hint: Look at the `SentenceTypeAllChargesAtConvictionInContactEvent` variable.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "9d412a8d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9d412a8d",
        "outputId": "d7dafcb2-58a7-4af0-966a-0f057744a058"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question Q1.1\n",
            "❌Examples that became NaN (bad formatting or non-numeric):\n",
            "Empty DataFrame\n",
            "Columns: [_Price_raw, Price_clean]\n",
            "Index: [] \n",
            "\n",
            "✅Examples with commas cleaned out:\n",
            "     _Price_raw  Price_clean\n",
            "101       1,990         1990\n",
            "263       1,000         1000\n",
            "764       1,200         1200\n",
            "1272      1,000         1000\n",
            "1275      5,000         5000\n",
            "1476      3,000         3000\n",
            "1846      1,500         1500\n",
            "1973      1,200         1200\n",
            "1977      1,800         1800\n",
            "2095      1,300         1300 \n",
            "\n",
            "Summary of cleaned Price column:\n",
            "count    30478.000000\n",
            "mean       163.589737\n",
            "std        197.785454\n",
            "min         10.000000\n",
            "25%         80.000000\n",
            "50%        125.000000\n",
            "75%        195.000000\n",
            "max      10000.000000\n",
            "Name: Price_clean, dtype: float64 \n",
            "\n",
            "Total missing after cleaning: 0\n",
            "Question Q1.2\n",
            "Proportion missing: 76.19%\n",
            "\n",
            "Value counts (including missing):\n",
            "subject_injury_clean\n",
            "NaN    9848\n",
            "Yes    1631\n",
            "No     1446\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Cross-tab of injury status vs. force_type (row proportions):\n",
            "force_type            Baton  Bodily Force  Chemical Irritant  Firearm  \\\n",
            "subject_injury_clean                                                    \n",
            "Missing               0.000         0.716              0.144    0.000   \n",
            "No                    0.000         0.756              0.091    0.001   \n",
            "Yes                   0.001         0.788              0.025    0.000   \n",
            "\n",
            "force_type            Gun Point Display  Improvised Weapon  Less Lethal  \\\n",
            "subject_injury_clean                                                      \n",
            "Missing                           0.003              0.008        0.009   \n",
            "No                                0.023              0.024        0.000   \n",
            "Yes                               0.027              0.025        0.000   \n",
            "\n",
            "force_type            Less Lethal Projectile  Maximal Restraint Technique  \\\n",
            "subject_injury_clean                                                        \n",
            "Missing                                0.000                        0.017   \n",
            "No                                     0.001                        0.000   \n",
            "Yes                                    0.001                        0.000   \n",
            "\n",
            "force_type            Police K9 Bite  Taser  \n",
            "subject_injury_clean                         \n",
            "Missing                        0.003  0.100  \n",
            "No                             0.001  0.104  \n",
            "Yes                            0.027  0.105  \n",
            "Question Q1.3\n",
            "Counts after cleaning (0=No, 1=Yes, NaN=Missing):\n",
            "ReleasedPretrial_dummy\n",
            "1.0    19154\n",
            "0.0     3801\n",
            "NaN       31\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Proportion missing: 0.13%\n",
            "\n",
            "Before vs After (first 10 rows):\n",
            "   WhetherDefendantWasReleasedPretrial  ReleasedPretrial_dummy\n",
            "0                                    9                     NaN\n",
            "1                                    0                     0.0\n",
            "2                                    0                     0.0\n",
            "3                                    0                     0.0\n",
            "4                                    1                     1.0\n",
            "5                                    0                     0.0\n",
            "6                                    1                     1.0\n",
            "7                                    1                     1.0\n",
            "8                                    0                     0.0\n",
            "9                                    1                     1.0\n",
            "Question Q1.4\n",
            "Total missing after cleaning: 9053\n",
            "Proportion missing: 0.3938484294788132\n",
            "\n",
            "Proportion missing by sentence type:\n",
            "Sentence_months                                   False  True \n",
            "SentenceTypeAllChargesAtConvictionInContactEvent              \n",
            "0                                                   1.0    0.0\n",
            "1                                                   1.0    0.0\n",
            "2                                                   1.0    0.0\n",
            "4                                                   0.0    1.0\n",
            "9                                                   0.0    1.0\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "## Question Q1.1\n",
        "\n",
        "url_airbnb = \"https://raw.githubusercontent.com/KendallFreese/wrangling_assignment/main/data/airbnb_hw.csv\"\n",
        "air = pd.read_csv(url_airbnb)\n",
        "\n",
        "# Keep original for comparison\n",
        "air[\"_Price_raw\"] = air[\"Price\"].astype(str)\n",
        "\n",
        "# Clean Price: remove $, commas → numeric (with coercion)\n",
        "air[\"Price_clean\"] = pd.to_numeric(\n",
        "    air[\"_Price_raw\"].str.replace(r\"[$,]\", \"\", regex=True),\n",
        "    errors=\"coerce\"\n",
        ")\n",
        "\n",
        "print(\"Question Q1.1\")\n",
        "\n",
        "nan_examples = air.loc[air[\"Price_clean\"].isna(), [\"_Price_raw\", \"Price_clean\"]].head(10)\n",
        "print(\"❌Examples that became NaN (bad formatting or non-numeric):\")\n",
        "print(nan_examples, \"\\n\")\n",
        "\n",
        "# Show values that had commas removed\n",
        "comma_examples = air.loc[air[\"_Price_raw\"].str.contains(\",\"), [\"_Price_raw\", \"Price_clean\"]].head(10)\n",
        "print(\"✅Examples with commas cleaned out:\")\n",
        "print(comma_examples, \"\\n\")\n",
        "\n",
        "print(\"Summary of cleaned Price column:\")\n",
        "print(air[\"Price_clean\"].describe(), \"\\n\")\n",
        "print(\"Total missing after cleaning:\", air[\"Price_clean\"].isna().sum())\n",
        "\n",
        "\n",
        "# The Price column contained dollar signs and commas (e.g., \"$1,112\"), which prevented pandas from reading it as numeric.\n",
        "# I removed these formatting characters and used pd.to_numeric(..., errors=\"coerce\") so valid values converted to floats\n",
        "# (e.g., \"1,990\" to 1990.0) while any problematic entries would safely become NaN. This ensures the variable can be used\n",
        "# for calculations and analysis.\n",
        "\n",
        "\n",
        "## Question Q1.2\n",
        "print(\"Question Q1.2\")\n",
        "\n",
        "url_mn = \"https://raw.githubusercontent.com/KendallFreese/wrangling_assignment/main/data/mn_police_use_of_force.csv\"\n",
        "mn = pd.read_csv(url_mn)\n",
        "\n",
        "#'Yes', 'No', and NaN\n",
        "mn[\"subject_injury_clean\"] = mn[\"subject_injury\"].map({\"Yes\": \"Yes\", \"No\": \"No\"})\n",
        "\n",
        "#  Proportion missing\n",
        "prop_missing = mn[\"subject_injury_clean\"].isna().mean()\n",
        "print(f\"Proportion missing: {prop_missing:.2%}\")\n",
        "\n",
        "# Counts\n",
        "print(\"\\nValue counts (including missing):\")\n",
        "print(mn[\"subject_injury_clean\"].value_counts(dropna=False))\n",
        "\n",
        "# Cross-tab with force_type\n",
        "ct = pd.crosstab(\n",
        "    mn[\"subject_injury_clean\"].fillna(\"Missing\"),\n",
        "    mn[\"force_type\"].fillna(\"Missing\"),\n",
        "    normalize=\"index\"\n",
        ").round(3)\n",
        "\n",
        "print(\"\\nCross-tab of injury status vs. force_type (row proportions):\")\n",
        "print(ct.head(10))   # show first 10 rows\n",
        "\n",
        "\n",
        "# The subject_injury variable was already coded as \"Yes\", \"No\", and missing (NaN). I preserved \"Yes\" and\n",
        "# \"No\" and left missing values as NaN, which matches the requirement: \"Yes\" when a person was injured, \"No\"\n",
        "# when no injury occurred. The output shows that about 76.19% of the data are missing. This level is a concern\n",
        "# because it reduces the reliability of any analysis that depends on injury outcomes. The crosstab of\n",
        "# subject_injury_clean with force_type shows how the likelihood of injury varies by type of force used. Missing\n",
        "# values are not evenly distributed: some force types have much higher missing rates than others. Since missingness\n",
        "# clusters around certain force_type categories, the data are likely not missing completely at random. This could\n",
        "# reflect differences in reporting practices (e.g., injuries less likely to be recorded when specific force types are used).\n",
        "\n",
        "print(\"Question Q1.3\")\n",
        "\n",
        "justiceurl = 'http://www.vcsc.virginia.gov/pretrialdataproject/October%202017%20Cohort_Virginia%20Pretrial%20Data%20Project_Deidentified%20FINAL%20Update_10272021.csv'\n",
        "justice = pd.read_csv(justiceurl,low_memory=False)\n",
        "\n",
        "# Clean WhetherDefendantWasReleasedPretrial\n",
        "justice[\"ReleasedPretrial_dummy\"] = justice[\"WhetherDefendantWasReleasedPretrial\"].replace({\n",
        "    1: 1,    # Released pretrial\n",
        "    0: 0,    # Not released pretrial\n",
        "    9: np.nan  # Missing\n",
        "})\n",
        "\n",
        "# Check counts\n",
        "print(\"Counts after cleaning (0=No, 1=Yes, NaN=Missing):\")\n",
        "print(justice[\"ReleasedPretrial_dummy\"].value_counts(dropna=False))\n",
        "\n",
        "# Proportion missing\n",
        "prop_missing = justice[\"ReleasedPretrial_dummy\"].isna().mean()\n",
        "print(f\"\\nProportion missing: {prop_missing:.2%}\")\n",
        "\n",
        "# Show first few rows before vs after\n",
        "print(\"\\nBefore vs After (first 10 rows):\")\n",
        "print(justice[[\"WhetherDefendantWasReleasedPretrial\", \"ReleasedPretrial_dummy\"]].head(10))\n",
        "\n",
        "# I recoded this into a proper dummy variable: 1 means the defendant was released pretrial, 0 means not released,\n",
        "# and 9 was replaced with NaN to correctly represent missing values.\n",
        "\n",
        "\n",
        "print(\"Question Q1.4\")\n",
        "\n",
        "# Columns of interest\n",
        "sent_raw  = \"ImposedSentenceAllChargeInContactEvent\"\n",
        "sent_type = \"SentenceTypeAllChargesAtConvictionInContactEvent\"\n",
        "\n",
        "# Clean imposed sentence into months\n",
        "def parse_sentence(x):\n",
        "    if pd.isna(x):\n",
        "        return np.nan\n",
        "    s = str(x).lower().strip()\n",
        "\n",
        "    # extract numeric part\n",
        "    m = re.search(r\"(\\d+(\\.\\d+)?)\", s)\n",
        "    if not m:\n",
        "        return np.nan\n",
        "    val = float(m.group(1))\n",
        "\n",
        "    # convert to months\n",
        "    if \"year\" in s:\n",
        "        return val * 12\n",
        "    elif \"day\" in s:\n",
        "        return val / 30.0\n",
        "    else:\n",
        "        return val  # assume months\n",
        "\n",
        "justice[\"Sentence_months\"] = justice[sent_raw].apply(parse_sentence)\n",
        "\n",
        "# Summary of missing\n",
        "print(\"Total missing after cleaning:\", justice[\"Sentence_months\"].isna().sum())\n",
        "print(\"Proportion missing:\", justice[\"Sentence_months\"].isna().mean())\n",
        "\n",
        "# Check patterns of missingness by sentence type\n",
        "ct = pd.crosstab(\n",
        "    justice[sent_type].fillna(\"Missing\"),\n",
        "    justice[\"Sentence_months\"].isna(),\n",
        "    normalize=\"index\"\n",
        ").round(3)\n",
        "\n",
        "print(\"\\nProportion missing by sentence type:\")\n",
        "print(ct.head(12))\n",
        "\n",
        "# I cleaned ImposedSentenceAllChargeInContactEvent variable into months by parsing days, months, and years into a common unit.\n",
        "# About 39% of the data are missing, which is a substantial proportion. The missingness is not random as certain sentence types\n",
        "# (codes 4 and 9) are always missing, while others (0, 1, 2) are always complete. This pattern suggests the missing values are\n",
        "# related to sentence type, meaning they are not missing at random."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a60a44e",
      "metadata": {
        "id": "5a60a44e"
      },
      "source": [
        "**Q2.** Go to https://sharkattackfile.net/ and download their dataset on shark attacks (Hint: `GSAF5.xls`).\n",
        "\n",
        "1. Open the shark attack file using Pandas. It is probably not a csv file, so `read_csv` won't work.\n",
        "2. Drop any columns that do not contain data.\n",
        "3. Clean the year variable. Describe the range of values you see. Filter the rows to focus on attacks since 1940. Are attacks increasing, decreasing, or remaining constant over time?\n",
        "4. Clean the Age variable and make a histogram of the ages of the victims.\n",
        "5. What proportion of victims are male?\n",
        "6. Clean the `Type` variable so it only takes three values: Provoked and Unprovoked and Unknown. What proportion of attacks are unprovoked?\n",
        "7. Clean the `Fatal Y/N` variable so it only takes three values: Y, N, and Unknown.\n",
        "8. Are sharks more likely to launch unprovoked attacks on men or women? Is the attack more or less likely to be fatal when the attack is provoked or unprovoked? Is it more or less likely to be fatal when the victim is male or female? How do you feel about sharks?\n",
        "9. What proportion of attacks appear to be by white sharks? (Hint: `str.split()` makes a vector of text values into a list of lists, split by spaces.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "a3f03830",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3f03830",
        "outputId": "93472a9d-4383-49b3-f1b7-d857862538c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question Q2.1\n",
            "Shape: (7042, 23)\n",
            "Question Q2.2\n",
            "Dropped columns: ['pdf', 'href formula', 'href', 'Case Number', 'Case Number.1', 'original order', 'Unnamed: 21', 'Unnamed: 22']\n",
            "Remaining columns: ['Date', 'Year', 'Type', 'Country', 'State', 'Location', 'Activity', 'Name', 'Sex', 'Age', 'Injury', 'Fatal Y/N', 'Time', 'Species ', 'Source']\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# from google.colab import files\n",
        "# uploaded = files.upload()\n",
        "\n",
        "print(\"Question Q2.1\")\n",
        "# Read in the Excel file\n",
        "sharkdata = pd.read_excel(\"sharkdata.xlsx\", engine=\"openpyxl\")\n",
        "\n",
        "# Look at the shape and first few rows\n",
        "print(\"Shape:\", sharkdata.shape)\n",
        "sharkdata.head()\n",
        "\n",
        "print(\"Question Q2.2\")\n",
        "# Identify columns that are completely empty\n",
        "empty_cols = [c for c in sharkdata.columns if sharkdata[c].isna().all()]\n",
        "\n",
        "# Define known artifact/metadata columns to remove\n",
        "artifact_cols = [\n",
        "    \"pdf\", \"href formula\", \"href\",\n",
        "    \"Case Number\", \"Case Number.1\", \"original order\"\n",
        "]\n",
        "\n",
        "# Drop also any \"Unnamed\" placeholder columns\n",
        "unnamed_cols = [c for c in sharkdata.columns if \"Unnamed\" in c]\n",
        "\n",
        "# Combine all to_drop lists\n",
        "cols_to_drop = empty_cols + artifact_cols + unnamed_cols\n",
        "\n",
        "# Cleaned data\n",
        "sharkdata_clean = sharkdata.drop(columns=[c for c in cols_to_drop if c in sharkdata.columns])\n",
        "\n",
        "print(\"Dropped columns:\", [c for c in cols_to_drop if c in sharkdata.columns])\n",
        "print(\"Remaining columns:\", sharkdata_clean.columns.tolist())\n",
        "\n",
        "print(\"Question Q2.3\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}